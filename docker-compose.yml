
version: "3.8"

x-common-env-vars: &common-env-vars
  DOCKERIZED: "True"
  REDIS_HOST: "redis"
  POSTGRES_HOST: "postgres"

services:
  webserver:
    image: "ghcr.io/modularhistory/webserver:$SHA"
    depends_on:
      - next
    deploy:
      restart_policy:
        condition: on-failure
    env_file: .env
    environment:
      DOMAINS: "modularhistory.com,www.modularhistory.com"
    ports:
      - "80:8080"
      - "443:8443"
    volumes:
      - ./_media:/modularhistory/_media
      - ./_static:/modularhistory/_static
    networks:
      default:
        ipv4_address: 172.27.0.5

  next:
    image: "ghcr.io/modularhistory/next:$SHA"
    command: npm run start
    depends_on:
      - django
      - celery
      - celery_beat
    deploy:
      restart_policy:
        condition: on-failure
    env_file: .env
    environment:
      NEXTAUTH_URL: "https://www.modularhistory.com"
      NEXTAUTH_URL_INTERNAL: "http://next:3000"
    expose:
      - "3000"
    volumes:
      - ./_static:/modularhistory/_static

  django:
    image: "ghcr.io/modularhistory/django:$SHA"
    command: bash config/scripts/init/django.sh
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    deploy:
      restart_policy:
        condition: on-failure
    env_file: .env
    environment:
      <<: *common-env-vars
      DJANGO_SETTINGS_MODULE: "core.settings"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl --fail http://localhost:8000/healthcheck/ || exit 1",
        ]
      timeout: 7s
      interval: 30s
      retries: 3
      start_period: 75s
    expose:
      - "8000"
    user: www-data
    volumes:
      # NOTE: www-data must be granted permission to write to these directories
      # both in the container and on the host machine. Permissions to write in
      # the container are granted in Dockerfile.django. Permissions to write on
      # the host machine must be granted manually; e.g.,
      #     sudo chown -R www-data:www-data .backups && sudo chmod g+w -R .backups
      - ./.backups:/modularhistory/.backups
      - ./.init:/modularhistory/.init
      - ./_static:/modularhistory/_static
      - ./_media:/modularhistory/_media

  celery:
    image: "ghcr.io/modularhistory/django:$SHA"
    command: bash config/scripts/init/celery.sh
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      django:
        condition: service_healthy
    deploy:
      restart_policy:
        condition: on-failure
    env_file: .env
    environment:
      <<: *common-env-vars
      IS_CELERY: "True"
    healthcheck:
      test: celery -A core inspect ping -d celery@$$HOSTNAME
      timeout: 30s
      interval: 30s
      retries: 3
      start_period: 20s
    user: www-data
    volumes:
      - ./.backups:/modularhistory/.backups
      - ./.init:/modularhistory/.init
      - ./_static:/modularhistory/_static
      - ./_media:/modularhistory/_media

  celery_beat:
    image: "ghcr.io/modularhistory/django:$SHA"
    command: bash config/scripts/init/celery_beat.sh
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      celery:
        condition: service_healthy
    deploy:
      restart_policy:
        condition: on-failure
    env_file: .env
    environment:
      <<: *common-env-vars

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.13.2
    deploy:
      restart_policy:
        condition: on-failure
    environment:
      # https://www.elastic.co/guide/en/elasticsearch/reference/current/important-settings.html
      - node.name=modularhistory-es
      - cluster.name=es-docker-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - xpack.ml.enabled=false
      - "ES_JAVA_OPTS=-Xms1536m -Xmx1536m"
    expose:
      - "9200"
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 30s
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - search_data:/usr/share/elasticsearch/data

  kibana:
    image: docker.elastic.co/kibana/kibana:7.8.1
    depends_on:
      - elasticsearch
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    expose:
      - "5601"

  # mongo:
  #   deploy:
  #     restart_policy:
  #       condition: on-failure
  #       max_attempts: 3
  #   env_file: .env
  #   healthcheck:
  #     test: echo 'db.runCommand("ping").ok' | mongo localhost:27017/test --quiet
  #     interval: 10s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 20s
  #   image: mongo
  #   expose:
  #     - "27017"
  #   volumes:
  #     - data:/data

  postgres:
    image: postgres
    deploy:
      restart_policy:
        condition: any
    env_file: .env
    expose:
      - "5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./.init:/docker-entrypoint-initdb.d

  redis:
    image: redis
    deploy:
      restart_policy:
        condition: on-failure
    expose:
      - "6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 20s
      timeout: 10s
      retries: 3
      start_period: 20s
    volumes:
      - "data:/data"

  redisinsight:
    image: redislabs/redisinsight:latest
    profiles: ["debug"]
    depends_on:
      - redis
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 3
    env_file: .env
    environment:
      REDIS_HOSTS: "local:redis:6379"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl --fail http://localhost:8002/healthcheck/ || exit 1",
        ]
      timeout: 7s
      interval: 15s
      retries: 2
      start_period: 10s
    ports:
      - "8002:8002"
    volumes:
      - "redisinsight:/db"
  
  cypress:
    # https://github.com/cypress-io/cypress-docker-images
    image: "cypress/included:7.1.0"
    depends_on:
      webserver:
        condition: service_healthy
    environment:
      - CYPRESS_baseUrl=https://www.modularhistory.com/
    working_dir: /e2e
    volumes:
      - ./frontend/cypress:/e2e/cypress
      - ./frontend/cypress.json:/e2e/cypress.json

networks:
  default:
    driver: bridge
    ipam:
      config:
        - subnet: 172.27.0.0/24

volumes:
  # `data` is used by both redis and mongodb
  data:
  letsencrypt:
  certbot:
  postgres_data:
  search_data:
  redisinsight:
